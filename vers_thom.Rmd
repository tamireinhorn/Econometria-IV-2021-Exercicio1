---
title: "Exercise 1"
output: html_notebook
fig_width: 6 
fig_height: 4 
---

## **1. LOADING PACKAGES**

```{r}

library(dreamerr)
library(tidyverse)
library(HARModel)
library(dplyr)
library(tsibble)
library(feasts)
library(stringr)
library(lubridate)
library(anytime)
library(ggplot2)
library(ggthemes)
library(knitr)
library(kableExtra)
library(DT)
library(htmltools)
library(reshape2) #to be used with tidyverse and gglopt2
library(ggpubr)
library(glmnet)
library(maditr)
source('Misc.R')  ##This calls the file with our auxiliary functions, keeping our code clean.

```

## **2. DATA PREPARATION**

The function clean_data will be created to clean the files, and it will be applied in the second chunk of the code, in which we will import the files.

```{r}
clean_data <- function(ticker) {

  ##In this function, we're going to first convert the Date column to date:
 
     ticker$Date <- as.Date(ticker$Date, '%m/%d/%Y')
  
  ## Then, we want to restrict it from 2000 onwards

     new_ticker <- filter(ticker, format(ticker$Date, '%Y') >= 2000)

     ##We need all days to contain the same number ofminutes, so we will use the left_join command first ensure that, and also to create NA for all MINUTES for which certain stocks do not have data.
     
     minute_list <- sort(unique(new_ticker$Time)) 
     day_list <- sort(unique(new_ticker$Date))
     minute_df <- data.frame('Time' = minute_list) ##A minute df is needed for the left_join() to be applied
     day_df <- data.frame('Date' = day_list) ##A day df is needed for the left_join() to be applied
     day_minute_df <- left_join(day_df, minute_df, character()) ##A df is created in which all 390 possible minutes were joined into each possible day
     new_ticker <- left_join(day_minute_df, new_ticker, by = c('Time', 'Date')) ##Then we left join all the informations in the new ticker into the day_minute df, uniformising all dates for all stocks in number of minutes
     new_ticker$minute_return <- (new_ticker$Close - lag(new_ticker$Close))/ new_ticker$Close ##Return taken on levels: p_t - p_{t-1} / p_{t-1}
     new_ticker$minute_log_return <- log(new_ticker$Close) - log(lag(new_ticker$Close)) ##Log return: log(p_t) - log(p_{t-1})
     
  return(new_ticker)
}
```

Given the clean_data() function above, we will now jointly import and clean the data (alternatively, we could have importer everything, then created the cleaning function and then have applied it, using three different chunks). 


```{r}
files_list <- list.files('Data')
stock_name <- str_remove(files_list, ".txt")
stock_list <- vector(mode = "list", length = 30) ##Initialize the stock list.
for (i in 1:length(stock_list)) {
  stock_df <- data.frame(read_csv(paste('Data/',files_list[i], sep = ""), col_types = cols())) 
  clean_stock_df <- clean_data(stock_df)
  stock_list[[i]] <- clean_stock_df[,]
}

names(stock_list) <- stock_name
```

A function to compute daily variables of interest will be created, and in a following code it will be applied to our list of stocks. These variables of interest are the realized volatility, sum of daily minute returns and sum of daily volumes traded per minute:

```{r}

#First for AXP, to understand the logic
#AXP %>% group_by(Date) %>% summarise(daily=sum(minute_log_return,na.rm=T), RV = sum(minute_log_return^2, na.rm = T), VOL = sum(Volume, na.rm = T), log_RV = log(sum(minute_log_return^2, na.rm = T)) ) ##This works as intended, just creates our daily dataframe. Therefore

##This logic will be turned into a function that creates daily dataframes for all of the tickers

make_daily_data <- function(clean_ticker){
  daily_ticker <- clean_ticker %>% group_by(Date) %>% summarise(daily=sum(minute_log_return,na.rm=T), RV = sum(minute_log_return^2, na.rm = T), VOL = sum(Volume, na.rm = T), log_RV = log(sum(minute_log_return^2, na.rm = T)) )
  #return(daily_ticker)
}
```

Now, we apply this function for all tickers, just like before.

```{r}
daily_stock_list <- vector(mode = 'list', length = 30) ##Initialize the daily stock list.

for (i in 1:length(stock_list)) {

  daily_stock_df <- make_daily_data(stock_list[[i]])
  daily_stock_list[[i]] <- daily_stock_df[,]
  
}
names(daily_stock_list) <- stock_name
```

As suggested, we should try creating one giant dataframe in order to use facet_wrap and plot everything at once.

```{r}
complete_daily_df <- bind_rows(daily_stock_list, .id = "column_label")
##I just want the name to be Stock:
names(complete_daily_df)[names(complete_daily_df)== 'column_label'] <- 'Stock'
```

## **3. PLOTS**

**Histogram of RV:**

```{r fig.height = 30, fig.width = 14}
ggplot(complete_daily_df, aes(x = RV)) +
  geom_histogram(aes(y = ..density..),binwidth = 0.0001, color = "darkblue", fill = "lightblue") + 
  labs(title = "RV Histograms", x = "", y = "")   + xlim(0, 0.01) +  facet_wrap(~ Stock, ncol = 3) +
  theme_minimal()
```

**Histogram of log RV:**

```{r fig.height = 30, fig.width = 14}

ggplot(complete_daily_df, aes(x = log_RV)) +
  geom_histogram(aes(y = ..density..),binwidth = 0.0001, color = "darkblue", fill = "lightblue") + 
  labs(title = "log(RV) Histograms", x = "", y = "")   + xlim(0, 0.01) +  facet_wrap(~ Stock, ncol = 3) +
  theme_minimal()

```

**Time Series of RV**

```{r fig.height = 30, fig.width = 14}

#test <- complete_daily_df %>%
#        filter(Stock=="AXP")
#ggplot(test,aes(x=Date, y=100*RV))+geom_line

  plot <- ggplot(complete_daily_df, aes(x = Date, y= 100*RV)) +
  geom_line(size=1) +
  facet_wrap(~ Stock, ncol = 4, scales = 'free') +
  labs(x = "", y = "", title = 'RV Time Series (in percentage terms, %)') +
  theme_bw() + theme(legend.position = "none")

  plot
 

```

**Time Series of log_RV**

```{r fig.height = 30, fig.width = 14}

  plot_log_RV <- ggplot(complete_daily_df, aes(x = Date, y= 100*log_RV)) +
  geom_line(size=1) +
  facet_wrap(~ Stock, ncol = 4, scales = 'free') +
  labs(x = "", y = "", title = 'log(RV) Time Series (in percentage terms, %)') +
  theme_bw() + theme(legend.position = "none")

  plot_log_RV
```

**AUTOCORRELATION** :

We will use functions to obtain ACFs for both our data and for simulated AR processes using estimated coefficients of our data.

**ACF for RV and log(RV)**:

```{r fig.height = 40, fig.width = 14}

RV_tsibble <- complete_daily_df %>% select(Stock, Date, RV) %>%  as_tsibble(key = 'Stock', index = 'Date', regular = FALSE)

RV_tsibble %>% ACF(RV, lag_max = 200) %>% autoplot() + theme_bw() + labs(x = 'Lags', y = '')

#estimating an AR(1) process for RV of stock AXP:
#RV_AXP <- RV_tsibble %>% filter(Stock == "AXP")
#RV_AXP_AR1 <- arima(RV_AXP$RV , order = c(1, 0, 0))

#Via TidyVerse, we already generate the ACFs for both level and log RV

autocorr_f <- function(df){
  
  autocorr <- data.frame(matrix(data = seq(0,29,1), nrow = 30, ncol = 1))
  names(autocorr) <- c("Lag")   #seq(0,29,1) indicate that there are 30 lags of estimated ACFs, for each Stock. The above function generates, thus, one dataframe listing ACFs, for each Stock.
  
  autocorr$autocorr_level = acf(df$RV, lag.max = 29, pl = F)[[1]] %>% as.numeric() 
  autocorr$autocorr_log = acf(df$log_RV, lag.max = 29, pl = F)[[1]] %>% as.numeric()     #[[1]] selects the the values of the ACFs themselves, as the function acf() generates other objects that are not of interest
  
  #ACFs for AR Model
  
  autocorr$autocorr_ar_level = ARMAacf(ar = arima(df$RV, order = c(1, 0, 0))$coef[1], ma = 0, lag.max = 29) %>% as.numeric()   
  
#The ARMAacf simulates a model for coefficients we give as imput, and returns the ACFs. @coef[1] selects only the auto-regressive parameter, and not the intercept.
                                     
  autocorr$autocorr_ar_log = ARMAacf(ar = arima(df$log_RV, order = c(1, 0, 0))$coef[1], ma = 0, lag.max = 29) %>% as.numeric()
  
  return(autocorr)
     
}

#the argument autocorr that is taken by the function created above is here defined as being complete_daily_df, which we group_by() and then apply the function

autocorr <- complete_daily_df %>% 
  group_by(Stock) %>% 
  group_modify(~ autocorr_f(.x))


#Now let`s use tidyverse to plot the graphs of interest (for both RV and log RF, it would be interesting to plot bars of the observed ACFs alongside the theoretical ACFs of forecasted ARs)

```

Looking at the ACF for both RV and log(RV), it is easy to notice that the plots present an approximate linear decay, whereas theoretical autoregressive processes contain ACFs that decay exponentially. 

**3. BENCHMARK MODEL**

We will now conduct an estimation of a HAR Model for the realized volatility for each Stock in our sample. With the estimated coefficients, we will simulate a HAR process in order to obtain a theoretical ACF and compare it with the empirical one. Before doing these procedures, we can already note that, from the empirical ACFs calculated over our data, the realised volatility presents a strong persistence over time, and this can be expressed by the rather linear decay observed in the ACF functions. Corsi (2009) notes that the purpose of reproducing the
long memory of empirical volatility seems be fully achieved by estimating HAR processes for actual data. If we focus on the period of time spanning our sample, approximately 17 years, allowing for less lags, there is a relatively linear decay in the figures of Corsi (2009) that indicate that the HAR model can be effective in reproducing actual volatility.


Trying to estimate da HAR models in a similar way to the AR process in the descriptive analysis

```{r}
autocorr_har_f <- function(df){
  
  autocorr_har <- data.frame(matrix(data = seq(0,29,1), nrow = 30, ncol = 1))
  names(autocorr) <- c("Lag")   #same as for the AR case. For df, we generate 30 rows, where ultimately the ACFs for each lag will be stored as we apply autocorr_har_f() over a df.
  
  autocorr_har$autocorr_level = acf(df$RV, lag.max = 29, pl = F)[[1]] %>% as.numeric() 
  autocorr_har$autocorr_log = acf(df$log_RV, lag.max = 29, pl = F)[[1]] %>% as.numeric()     #same as for the AR case
  
#Estimating the HAR Models
  
har_est_rv <- HAREstimate(RM = df$RV, periods = c(1,5,22))

har_est_log_rv <- HAREstimate(RM = df$log_RV, periods = c(1,5,22))

#Extracting the estimated coefficients and simulating theoretical processes with those coefficients:

har_sim_rv <- HARSimulate(len=1500, periods = c(1, 5, 22), coef=coef(har_est_rv), errorTermSD = 0.001) 

har_sim_log_rv <- HARSimulate(len=1500, periods = c(1, 5, 22), coef=coef(har_est_log_rv), errorTermSD = 0.001) 

#ACFs for simulated HAR Models
  
autocorr_har$autocorr_har_level = acf(har_sim_rv, lag.max = 29) %>% as.numeric()   

autocorr_har$autocorr_har_log = acf(har_sim_log_rv, lag.max = 29) %>% as.numeric()
  
  return(autocorr_har)
}

#the argument autocorr that is taken by the function created above is here defined as being complete_daily_df, our working dataframe, which we group_by() and then apply the function

autocorr_har <- complete_daily_df %>% 
  group_by(Stock) %>% 
  group_modify(~ autocorr_har_f(.x))
```


**Rolling Window Estimations**

Below, we will first conduct a rolling window estimation for RV of company AXP and try to generalize the method to the other companies via tidyverse and group_map() or group_modify()

```{r}

df <- complete_daily_df %>% filter(Stock == 'AXP')


##Rolling Window of size N
N <- 1000 #This is the size of our rolling window
days <- dim(df)[[1]] ##This is the complete size of our sample!
i = 1
lambda_seq <- 10^seq(2, -2, by = -.1) ##I need to create a sequence of possible lambdas, just to use.
##Later, this will be the hyperparameter tuning we will decide!
 ##First, how do I estimate a ridge regression with all the data?
## GLMNET only works with matrices. Therefore, we need to convert the data, separating it between dependent and independent:


## The dependent variable is RV of all other stocks other than SPY. Should we keep V out as well?

ridge_model <- glmnet()
##I need to be in observation 22 so that I have the past 21 observations for RV_{m,t}
##My rolling window will be of size 10. ##So i need to have
##22 to 31, ##23 to 32, etc
##My intervals are then i + 21 to N + 21 + i -1!
N <- 3
i <- 1
print(i+21)
##18 = (22) - x 
##18 - 22 = -x
## x= 6
##18 = (21 + i) -6
print(N+21+i-1)
print(21 + i -4)
small_df <- df[(i+21):(N+i+21-1),]  
##For RV_m, i need 22 observations, from 22 to 1
##This puts me at i + 21, the first element of the interval
##To i.
##But this could be read as i + 21 (i = 1, 22) to (i+ 21) - (22, intervalsize- 1)) 
#RV_W is 5, so i+21 (i=1, 22) to 18, right?
#to (i+ 21) - (5) -1 => 22 - 4 = 18 
RV_m <- 1/22 *sum((df$RV[(i+21):i]))
RV_w <- 1/5 * sum(df$RV[(i+21):(i+21-4)])
RV_t <- df$RV[(i+21)-1]
##I also need to get all stocks but SPY in a single line
x_df <- complete_daily_df %>% filter(Stock != 'SPY')
##Now, I want to make this WIDE
x_long <- x_df %>% select(Stock, Date, RV) %>% dcast(Date ~ Stock, value.var = 'RV')
RV_wide <-  x_df %>% select(Stock, Date, RV) %>% dcast(Date ~ Stock, value.var = 'RV')
logRV_wide <-  x_df %>% select(Stock, Date, log_RV) %>% dcast(Date ~ Stock, value.var = 'log_RV')
RV_wide$RV_m <- RV_m
days <-  dim(key_stock_df)[[1]] ##This will give us the length of our 
month <- 22
week <- 5
key_stock_df <- complete_daily_df
window_size <- 3
 RV_m <- vector(mode = list, length = 3)
day_list <- sort(unique(key_stock_df$Date)) 
key_stock <- 'SPY'
df <- complete_daily_df
 other_stock_df <- df %>% filter(Stock != key_stock) ##This will create a dataframe with all other stocks other than our dependent variable!
  
 
  
  wide_other_stock_df <- other_stock_df %>% select(Stock, Date, RV) %>% dcast(Date ~ Stock, value.var = chosen_variable)  ##This other_stock df needs to be wide!
  
  
  key_stock_df <- df %>% filter(Stock == key_stock) ##This, in turn, creates a df with ONLY the stock we want.
month <- 22
week <- 5
for(i in 20:45){ ##This cannot go on until days, this needs to stop at the last possible window. ##days - window_size +1 maybe
    
    beg <- i + (month - 1) ##Just to clear notation, I wanted to create this variable for the interval's beginning.
    key_window <- key_stock_df[(beg):(window_size - 1 + beg),]  ##This creates the data subset we wish to use ##TODO: should this use the COMPLETE df or the separate?
    other_window <- wide_other_stock_df [(beg):(window_size - 1 +beg ),]
    
    ##However, this does not seal the deal. Once inside this window, we need to construct the variables. This requires us to loop again?
    ##If our window_size is indeed 3, and we have observations 22, 23, 24, we need to build RV_m for all these
    ##RV_{m, 22} is 1/22 * sum(RV of 22 to 1), RV_{m,23} is 1/22 * sum(RV of 23 to 2), etc. 
    ##So RV_{m,i} needs to go from i+month-1 to i, then from i+month-1+1 to i+1, etc. 
    ##For week, we start at i+beg (22) and we need to go until 18, which means (i+beg) - (week - 1) = 
    RV_m <- vector(mode = 'list', length = window_size)
    RV_w <- vector(mode = 'list', length = window_size)
    RV_t <- vector(mode = 'list', length = window_size)
    current_date <- vector(mode = 'list', length = window_size)
    past_date <- vector(mode = 'list', length = window_size)
   
      for(k in 0:(window_size-1)){
        print(beg)
        RV_m[[(k+1)]] <- (1/month) * sum(( key_stock_df$RV[(beg+k):(i+k)]))
       ## print( key_stock_df$RV[(beg+k):(i+k)])
        RV_w[[(k+1)]]<- (1/week) * sum(( key_stock_df$RV[(beg+k):(beg+k - (week-1))]))
        RV_t[[(k+1)]] <- key_stock_df$RV[(beg+k-1)]
        current_date[[(k+1)]] <- as.Date(key_stock_df$Date[(beg+k)])
        past_date[[(k+1)]] <- as.Date(key_stock_df$Date[(beg+k-1)])
      
      }
  
  }
df2 <-  
  data.frame('month_RV' = unlist(I(RV_m)), 'week_RV' = unlist(I(RV_w)), 'previous_RV' = unlist(I(RV_t)), 'current_date' = unlist(I(current_date)), 'past_date' = unlist(I(past_date)))
                                                                                                    
                                                                                                    
df2$current_date <- as.Date(df2$current_date, origin = '1970-01-01') 

df2$past_date <- as.Date(df2$past_date, origin = '1970-01-01')                
df3 <- inner_join(df2, wide_other_stock_df, by = c('past_date' = 'Date' ))
df4 <- inner_join(df3, key_window, by = c('current_date' = 'Date'))
chosen_variable = 'RV'
df4 <- key_window %>% select(Date, VOL,chosen_variable) %>% inner_join(df3, by = c('Date' = 'current_date'))
df5 <- data.matrix(df4)
y_var <- data.matrix(df4$RV)
x_var <- data.matrix(df4[,!names(df4) %in% c('Date', 'VOL', 'RV', 'past_date', 'V')])
# Setting the range of lambda values
lambda_seq <- 10^seq(2, -2, by = -.1)
# Using glmnet function to build the ridge regression in r
fit <- glmnet(x_var, y_var, alpha = 0, lambda  = lambda_seq)
# Checking the model
summary(fit)
```
