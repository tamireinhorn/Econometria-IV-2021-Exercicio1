---
title: "Exercise 1"
output: html_notebook
fig_width: 6 
fig_height: 4 
---

## **1. LOADING PACKAGES**

```{r}

library(dreamerr)
library(tidyverse)
library(HARModel)
library(dplyr)
library(tsibble)
library(feasts)
library(stringr)
library(lubridate)
library(anytime)
library(ggplot2)
library(ggthemes)
library(knitr)
library(kableExtra)
library(DT)
library(htmltools)
library(reshape2) #to be used with tidyverse and gglopt2
library(ggpubr)
library(glmnet)
library(maditr)
library(broom)
library(devtools)
library(foreach)
library(forecast)
source('Misc.R')  ##This calls the file with our auxiliary functions, keeping our code clean.
install_github('gabrielrvsc/HDeconometrics')
library(HDeconometrics)
library(ipred)
library(boot)
library(tseries)
library(brnn)
library(randomForest)
install_github("hyanworkspace/rangerts")
library(rangerts)
```

## **2. DATA PREPARATION**

The function clean_data will be created to clean the files, and it will be applied in the second chunk of the code, in which we will import the files.

```{r}
clean_data <- function(ticker) {

  ##In this function, we're going to first convert the Date column to date:
 
     ticker$Date <- as.Date(ticker$Date, '%m/%d/%Y')
  
  ## Then, we want to restrict it from 2000 onwards

     new_ticker <- filter(ticker, format(ticker$Date, '%Y') >= 2000)

     ##We need all days to contain the same number ofminutes, so we will use the left_join command first ensure that, and also to create NA for all MINUTES for which certain stocks do not have data.
     
     minute_list <- sort(unique(new_ticker$Time)) 
     day_list <- sort(unique(new_ticker$Date))
     minute_df <- data.frame('Time' = minute_list) ##A minute df is needed for the left_join() to be applied
     day_df <- data.frame('Date' = day_list) ##A day df is needed for the left_join() to be applied
     day_minute_df <- left_join(day_df, minute_df, character()) ##A df is created in which all 390 possible minutes were joined into each possible day
     new_ticker <- left_join(day_minute_df, new_ticker, by = c('Time', 'Date')) ##Then we left join all the informations in the new ticker into the day_minute df, uniformising all dates for all stocks in number of minutes
     new_ticker$minute_return <- (new_ticker$Close - lag(new_ticker$Close))/ new_ticker$Close ##Return taken on levels: p_t - p_{t-1} / p_{t-1}
     new_ticker$minute_log_return <- log(new_ticker$Close) - log(lag(new_ticker$Close)) ##Log return: log(p_t) - log(p_{t-1})
     
  return(new_ticker)
}
```

Given the clean_data() function above, we will now jointly import and clean the data (alternatively, we could have importer everything, then created the cleaning function and then have applied it, using three different chunks). 


```{r}
files_list <- list.files('Data')
stock_name <- str_remove(files_list, ".txt")
stock_list <- vector(mode = "list", length = 29) ##Initialize the stock list.
for (i in 1:length(stock_list)) {
  stock_df <- data.frame(read_csv(paste('Data/',files_list[i], sep = ""), col_types = cols())) 
  clean_stock_df <- clean_data(stock_df)
  stock_list[[i]] <- clean_stock_df[,]
}

names(stock_list) <- stock_name
```

A function to compute daily variables of interest will be created, and in a following code it will be applied to our list of stocks. These variables of interest are the realized volatility, sum of daily minute returns and sum of daily volumes traded per minute:

```{r}

#First for AXP, to understand the logic
#AXP %>% group_by(Date) %>% summarise(daily=sum(minute_log_return,na.rm=T), RV = sum(minute_log_return^2, na.rm = T), VOL = sum(Volume, na.rm = T), log_RV = log(sum(minute_log_return^2, na.rm = T)) ) ##This works as intended, just creates our daily dataframe. Therefore

##This logic will be turned into a function that creates daily dataframes for all of the tickers

make_daily_data <- function(clean_ticker){
  daily_ticker <- clean_ticker %>% group_by(Date) %>% summarise(daily=sum(minute_log_return,na.rm=T), RV = sum(minute_log_return^2, na.rm = T), VOL = sum(Volume, na.rm = T), log_RV = log(sum(minute_log_return^2, na.rm = T)) )
  #return(daily_ticker)
}
```

Now, we apply this function for all tickers, just like before.

```{r}
daily_stock_list <- vector(mode = 'list', length = 29) ##Initialize the daily stock list.

for (i in 1:length(stock_list)) {

  daily_stock_df <- make_daily_data(stock_list[[i]])
  daily_stock_list[[i]] <- daily_stock_df[,]
  
}
names(daily_stock_list) <- stock_name
```


As suggested, we should try creating one giant dataframe in order to use facet_wrap and plot everything at once.

```{r}
complete_daily_df <- bind_rows(daily_stock_list, .id = "column_label")
##I just want the name to be Stock:
names(complete_daily_df)[names(complete_daily_df)== 'column_label'] <- 'Stock'
```




**Rolling Window Estimations**
```{r}
full_data <- VariableCreation(df = complete_daily_df) ##We use this function to create the desired variables.
complete_ML_set <- RollingWindow(full_data)

```
Now, we can extract the objects and calculate MSEs and do the Diebold-Mariano test.
```{r}
# betas_lasso <-complete_ML_set$betas_lasso 
# betas_ridge <- complete_ML_set$betas_ridge
# betas_adalasso <- complete_ML_set$betas_adalasso
# betas_elastic_net <- complete_ML_set$betas_elastic_net
# betas_ada_elastic_net <- complete_ML_set$betas_ada_elastic_net
betas_bagging <- complete_ML_set$betas_bagging
betas_csr <- complete_ML_set$betas_csr
MSE_har <- complete_ML_set$MSE_HAR
# MSE_ridge <- complete_ML_set$MSE_ridge
# MSE_lasso <- complete_ML_set$MSE_lasso
# MSE_adalasso <- complete_ML_set$MSE_adalasso
# MSE_elastic_net <- complete_ML_set$MSE_elastic_net
# MSE_ada_elastic_net <- complete_ML_set$MSE_ada_elastic_net
MSE_bagging <- complete_ML_set$MSE_bagging
MSE_csr <- complete_ML_set$MSE_csr
MSE_rf <- complete_ML_set$MSE_random_forest
MSE_nn <- complete_ML_set$MSE_nnbr
cat('The MSE for the benchmark model is' , mean(MSE_har), '\n')
# cat('The MSE for the ridge model relative to the benchmark is' , mean(MSE_ridge)/mean(MSE_har),'and its absolute value is',mean(MSE_ridge), '\n')
# cat('The MSE for the LASSO model relative to the benchmark is' , mean(MSE_lasso)/mean(MSE_har),'and its absolute value is',mean(MSE_lasso),'\n')
# cat('The MSE for the Adaptative Lasso model relative to the benchmark is' , mean(MSE_adalasso)/mean(MSE_har),'and its absolute value is',mean(MSE_adalasso), '\n')
# cat('The MSE for the Elastic Net model relative to the benchmark is' , mean(MSE_elastic_net)/mean(MSE_har),'and its absolute value is',mean(MSE_elastic_net), '\n')
# cat('The MSE for the Adaptative Elastic Net model relative to the benchmark is' , mean(MSE_ada_elastic_net)/mean(MSE_har), 'and its absolute value is',mean(MSE_ada_elastic_net),'\n')
cat('The MSE for the bagging model relative to the benchmark is' , mean(MSE_bagging)/mean(MSE_har), 'and its absolute value is',mean(MSE_bagging),'\n')
cat('The MSE for the neural network relative to the benchmark is' , mean(MSE_nn)/mean(MSE_har), 'and its absolute value is',mean(MSE_nn),'\n')
cat('The MSE for the random forest relative to the benchmark is' , mean(MSE_rf)/mean(MSE_har), 'and its absolute value is',mean(MSE_rf),'\n')
cat('The MSE for the complete subset regression model relative to the benchmark is' , mean(MSE_csr)/mean(MSE_har), 'and its absolute value is',mean(MSE_csr),'\n')
```
Now for the Diebold-Mariano test:
```{r}
# dm.test(MSE_har, MSE_ridge)
# dm.test(MSE_har, MSE_lasso)
# dm.test(MSE_har, MSE_adalasso)
# dm.test(MSE_har, MSE_elastic_net)
dm.test(MSE_har, MSE_nn)
dm.test(MSE_har, MSE_rf
        
        )
dm.test(MSE_har, MSE_bagging)

dm.test(MSE_har, MSE_csr)
```


Now, for the variable importance
```{r}

window_size <- 1000
y_var <- log(data.matrix(full_data$RV)) 
  
x_var <- log(data.matrix(full_data[,!names(full_data) %in% c('Date', 'RV', 'current_date')])) ##Here, I HAD to remove V, because it's NAN before 2008.

days <- dim(y_var)[[1]] 
num_windows <- days  - window_size

sd_matrix <- matrix(nrow = dim(x_var)[2], ncol = num_windows )

foreach (i = 1:num_windows) %do% {
 
  foreach(j = 1:dim(x_var)[[2]]) %do% {
    sd_matrix[j, i] <-  sd(x_var[i:(window_size+i-1),j])
  }
   
}
library(reshape2)
variable_importance_matrix_bagging <- data.frame(betas_bagging/sd_matrix)
variable_importance_matrix_bagging$variable <- colnames(x_var)
dfm_bag <- melt(variable_importance_matrix_bagging, id.vars = "variable",factorAsStrings = TRUE )


variable_importance_matrix_csr <- data.frame(betas_csr/sd_matrix)
variable_importance_matrix_csr$variable <- colnames(x_var)
dfm_csr <- melt(variable_importance_matrix_csr, id.vars = "variable",factorAsStrings = TRUE )
ggplot(dfm_csr) + geom_point(aes(x = variable.1, y = value, color = variable)) +labs(x = "", y = "") + labs(colour = NULL)
ggplot(dfm_bag) + geom_point(aes(x = variable.1, y = value, color = variable)) +labs(x = "", y = "") + labs(colour = NULL)


```
Random forest variable importance:

```{r}
rf_importance <- matrix(nrow = dim(x_var)[2], ncol = num_windows )
foreach (i = 1:num_windows) %do% {
  y <-  y_var[i:(window_size+i-1)]
  x <- x_var[i:(window_size+i-1),]
  z <- data.frame(x)
  z$y <- y
  rf_importance[,i] <- importance(rangerts::rangerts(y~ ., data = z,
                   num.trees = 100,
                   mtry = floor(sqrt(ncol(z))),
                   replace = T, # default = T too
                   seed = 1,
                   bootstrap.ts = "moving",
                   block.size = 365, importance = "impurity", verbose = FALSE))}
dfm_rf <- data.frame(rf_importance)
dfm_rf$variable <- colnames(x_var)
dfm_rf <- melt(dfm_rf, id.vars = "variable",factorAsStrings = TRUE  )
ggplot(dfm_rf) + geom_point(aes(x = variable.1, y = value, color = variable)) +labs(x = "", y = "") + labs(colour = NULL)

```
```{r}
rf_teste<-brnn(x,y,neurons=15, verbose = FALSE)

#Criar função predict para adequar ao caso do rangerts
custom_predict <- function(X.model, newdata) {
   predict(X.model, data.frame(newdata))$predictions}

rf_e<-explain(rf_teste,data=X_teste,y=y_teste,predict_function =custom_predict,model_info=list(package="brnn",ver="0.8",type="brnn"))

vi50_rf<-model_parts(explainer = rf_e, 
                   loss_function = loss_root_mean_square,
                               B = 50,
                                N=NULL,
                            type = "ratio")
```




